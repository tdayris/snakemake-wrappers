.. _`bio/gatk/baserecalibratorspark`:

GATK BASERECALIBRATORSPARK
==========================

Run gatk BaseRecalibratorSpark.


**URL**: https://gatk.broadinstitute.org/hc/en-us/articles/360036897372-BaseRecalibratorSpark-BETA-

Example
-------

This wrapper can be used in the following way:

.. code-block:: python

    rule gatk_baserecalibratorspark:
        input:
            bam="mapped/{sample}.bam",
            ref="genome.fasta",
            dict="genome.dict",
            known="dbsnp.vcf.gz"  # optional known sites
        output:
            recal_table="recal/{sample}.grp"
        log:
            "logs/gatk/baserecalibrator/{sample}.log"
        params:
            extra="",  # optional
            java_opts="", # optional
            #spark_runner="",  # optional, local by default
            #spark_0.50.4-2418-g8fefa1e53="",  # optional
            #spark_extra="", # optional
        resources:
            mem_mb=1024
        threads: 8
        wrapper:
            "0.50.4-2418-g8fefa1e53/bio/gatk/baserecalibratorspark"

Note that input, output and log file paths can be chosen freely.

When running with

.. code-block:: bash

    snakemake --use-conda

the software dependencies will be automatically deployed into an isolated environment before execution.

Software dependencies
---------------------

* ``gatk4==4.2.0.0``
* ``openjdk=8``
* ``snakemake-wrapper-utils=0.1.3``

Input/Output
------------
**Input:**

* ``bam``: Path to bam file
* ``ref``: Path to  fasta reference
* ``known``: Path to vcf.gz of known variants

**Output:**

* ``recal_table``: Path to recalibration table for the bam



Params
------

* ``java_opts``: The `java_opts` param allows for additional arguments to be passed to the java compiler, e.g. "-XX:ParallelGCThreads=10" (not for `-XmX` or `-Djava.io.tmpdir`, since they are handled automatically).

* ``extra``: The `extra` param allows for additional program arguments for `baserecalibratorspark`.

* ``spark_runner``: The `spark_runner` param = "LOCAL"|"SPARK"|"GCS" allows to set the spark_runner. Set the parameter to "LOCAL" or don't set it at all to run on local machine.

* ``spark_master``: The `spark_master` param allows to set the URL of the Spark Master to submit the job. Set to "local[number_of_cores]" for local execution. Don't set it at all for local execution with number of cores determined by snakemake.

* ``spark_extra``: The `spark_extra` param allows for additional spark arguments.





Authors
-------

* Christopher Schröder
* Johannes Köster
* Jake VanCampen


Code
----

.. code-block:: python

    __author__ = "Christopher Schröder"
    __copyright__ = "Copyright 2020, Christopher Schröder"
    __email__ = "christopher.schroeder@tu-dortmund.de"
    __license__ = "MIT"

    import tempfile

    from snakemake.shell import shell
    from snakemake_wrapper_utils.java import get_java_opts

    extra = snakemake.params.get("extra", "")
    spark_runner = snakemake.params.get("spark_runner", "LOCAL")
    spark_master = snakemake.params.get(
        "spark_master", "local[{}]".format(snakemake.threads)
    )
    spark_extra = snakemake.params.get("spark_extra", "")
    java_opts = get_java_opts(snakemake)

    tmpdir = tempfile.gettempdir()

    log = snakemake.log_fmt_shell(stdout=True, stderr=True)
    known = snakemake.input.get("known", "")
    if known:
        known = "--known-sites {}".format(known)

    shell(
        "gatk --java-options '{java_opts}' BaseRecalibratorSpark {extra} "
        "-R {snakemake.input.ref} -I {snakemake.input.bam} "
        "--output {snakemake.output.recal_table} {known} "
        "--tmp-dir {tmpdir} "
        "-- --spark-runner {spark_runner} --spark-master {spark_master} {spark_extra} "
        "{log}"
    )


.. |nl| raw:: html

   <br>