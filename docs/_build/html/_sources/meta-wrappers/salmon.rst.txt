.. _`salmon`:

SALMON
======

Pseudo map and quantify your reads over transcritome with `Salmon <https://salmon.readthedocs.io/en/latest/>`_


Example
-------

This meta-wrapper can be used by integrating the following into your workflow:

.. code-block:: python

    # example_salmon_config = {
    #     "genome": "path/to/sequence.fasta",
    #     "transcriptome": "path/to/transcriptome.fasta",
    #     "gentrome": "path/to/gentrome.fasta",
    #     "decoy": "/path/to/decoy.names.txt",
    #     "index": "path/to/salmon_index_dir"
    # }

    """
    This rule pseudo-map and quantifies your paired reads over the indexed
    reference.
    """
    rule salmon_quant_paired:
        input:
            r1="fastp/trimmed/pe/{sample}.1.fastq",
            r2="fastp/trimmed/pe/{sample}.2.fastq",
            index=ancient(config.get("index", "salmon/index")),
            gtf=ancient(config["gtf"])
        output:
            quant="salmon/pseudo_mapping/{sample}/quant.sf",
            lib="salmon/pseudo_mapping/{sample}/lib_format_counts.json",
            mapping=temp("salmon/bams/{sample}.bam")
        message: "Quantifying {wildcards.sample} with Salmon"
        threads: min(config.get("threads", 20), 20)
        resources:
            time_min=lambda wildcards, input, attempt: attempt * 45 * (input.size_mb / 10240),
            mem_mb=lambda wildcards, input, attempt: attempt * 1024 * 10 * (input.size_mb / 10240),
            tmpdir="tmp"
        params:
            libType = config.get("salmon_libtype", "A"),
            extra = config.get(
                "salmon_quant_extra",
                "--numBootstraps 100 --validateMappings --gcBias --seqBias --posBias"
            )
        log:
            "logs/salmon/quant/{sample}.log"
        wrapper:
            "bio/salmon/quant"


    """
    Index your transcriptome or gentrome file with Salmon in order to map your
    reads against this reference.

    These rules are cached since it should be used only once per reference genome.
    """
    rule salmon_index:
        input:
            sequences=config.get("gentrome", "salmon/decoy/gentrome.fasta"),
            decoy=config.get("decoy", "salmon/decoy/decoy.txt")
        output:
            index=temp(directory("salmon/index"))
        message: "Indexing transcriptome/gentrome sequences with Salmon"
        threads: min(config.get("threads", 20), 20)
        resources:
            time_min=lambda wildcards, attempt, input: (
                attempt * (120 if "decoy" in input.keys() else 45)
            ),
            mem_mb=lambda wildcards, attempt, input: (
                attempt * (25600 if "decoy" in input.keys() else 10240)
            ),
            tmpdir="tmp"
        params:
            extra=config.get("salmon_index_extra", "--keepDuplicates --gencode")
        log:
            "logs/salmon/index.log"
        wrapper:
            "bio/salmon/index"


    """
    This rule is optional in case you want to use decoy sequences within your
    transcriptome. See salmon documentation for more information.

    These rules are cached since it should be used only once per reference genome.
    """
    rule awk_create_exons_mask:
        input:
            config["gtf"]
        output:
            temp("salmon/decoy/exons.bed")
        message: "Building exons mask for decoy sequence identification"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 512,
            time_min=lambda wildcards, attempt: attempt * 15,
            tmpdir="tmp"
        log:
            "logs/awk/mask_exons.log"
        params:
            begin='FS=OFS="\t"',
            body=['if ($3=="exon") {{print $1,$4,$5}}']
        wrapper:
            "bio/awk"


    rule bedtools_mask_fasta:
        input:
            bed="salmon/decoy/exons.bed",
            fasta=config["genome"]
        output:
            temp("salmon/decoy/reference.masked.genome.fasta")
        message: "Masking genome sequences to aquire decoy"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 1024 * 2,
            time_min=lambda wildcards, attempt: attempt * 15,
            tmpdir="tmp"
        log:
            "logs/bedtools/maskfasta.log"
        params:
            extra=""
        wrapper:
            "bio/bedtools/maskfasta"


    rule mashmap_align_tx_to_masked_genome:
        input:
            fasta="salmon/decoy/reference.masked.genome.fasta",
            query=config["transcriptome"]
        output:
            temp("salmon/decoy/mashmap.masked.out")
        message: "Aligning transcriptome to genome"
        threads: 20
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 1024 * 82,
            time_min=lambda wildcards, attempt: attempt * 60 * 3,
            tmpdir="tmp"
        log:
            "logs/mashmap/mask.log"
        params:
            extra="--perc_identity 80 --segLength 500"
        wrapper:
            "bio/mashmap"


    rule awk_extract_intervals_from_mashmap:
        input:
            "salmon/decoy/mashmap.masked.out"
        output:
            temp("salmon/decoy/mashmap.masked.unsorted.bed")
        message: "Extracting intervals from mashmap alignments"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 512,
            time_min=lambda wildcards, attempt: attempt * 15,
            tmpdir="tmp"
        params:
            begin='FS=" "; OFS="\t"',
            body=['print $6,$8,$9']
        log:
            "logs/awk/extract_intervals_from_mashmap.log"
        wrapper:
            "bio/awk"


    rule sort_bed_intervals:
        input:
            "salmon/decoy/mashmap.masked.unsorted.bed"
        output:
            temp("salmon/decoy/mashmap.masked.sorted.bed")
        message: "Sorting extracted intervals"
        threads: 5
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 1024 * 4,
            time_min=lambda wildcards, attempt: attempt * 40,
            tmpdir="tmp"
        params:
            columns=["1,1", "2,2n"],
            extra=""
        log:
            "logs/sort/masked.bed.log"
        wrapper:
            "bio/sort"


    rule bedtools_merge_intervals:
        input:
            "salmon/decoy/mashmap.masked.sorted.bed"
        output:
            temp("salmon/decoy/mashmap.masked.merged.bed")
        message: "Merging the intervals"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 1024 * 2,
            time_min=lambda wildcards, attempt: attempt * 30,
            tmpdir="tmp"
        log:
            "logs/bedtools/merge/sorted_intevals.log"
        params:
            extra=""
        wrapper:
            "bio/bedtools/merge"


    rule bedtools_regenerate_relevant_sequences:
        input:
            fasta="salmon/decoy/reference.masked.genome.fasta",
            bed="salmon/decoy/mashmap.masked.merged.bed"
        message: "Extracting sequences from the genome"
        output:
            temp("salmon/decoy/genome.found.fasta")
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 1024 * 3,
            time_min=lambda wildcards, attempt: attempt * 45,
            tmpdir="tmp"
        log:
            "logs/bedtools/getfasta.log"
        params:
            extra=""
        wrapper:
            "bio/bedtools/getfasta"


    rule awk_concatenate_decoy_sequences:
        input:
            "salmon/decoy/genome.found.fasta"
        output:
            temp("salmon/decoy/decoy.fasta")
        message: "Concatenating to get decoy sequences"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 1024 * 1.5,
            time_min=lambda wildcards, attempt: attempt * 15,
            tmpdir="tmp"
        log:
            "logs/awk/concatenate_sequences.log"
        params:
            body=[
                'a=$0',
                'getline',
                'split(a, b, ":")',
                'r[b[1]] = r[b[1]]""$0'
            ],
            end='for (k in r) { print k"\\n"r[k] }'
        wrapper:
            "bio/awk"


    rule build_gentrome:
        input:
            transcriptome=config["transcriptome"],
            decoy="salmon/decoy/decoy.fasta"
        output:
            "salmon/decoy/gentrome.fasta"
        message: "Buiding gentrome sequences"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 512,
            time_min=lambda wildcards, attempt: attempt * 25,
            tmpdir="tmp"
        log:
            "logs/cat/gentrome.log"
        params:
            ""
        shell:
            "cat {input.transcriptome} {input.decoy} > {output} 2> {log}"


    rule extract_decoy_id:
        input:
            "salmon/decoy/decoy.fasta"
        output:
            "salmon/decoy/decoy.txt"
        message: "Extracting decoy sequences name"
        threads: 1
        resources:
            mem_mb=lambda wildcards, attempt: attempt * 512,
            time_min=lambda wildcards, attempt: attempt * 15,
            tmpdir="tmp"
        log:
            "logs/grep/decoy.log"
        params:
            "-P '^>'"
        shell:
            "grep {params} {input} > {output} 2> {log}"

Note that input, output and log file paths can be chosen freely, as long as the dependencies between the rules remain as listed here.
For additional parameters in each individual wrapper, please refer to their corresponding documentation (see links below).

When running with

.. code-block:: bash

    snakemake --use-conda

the software dependencies will be automatically deployed into an isolated environment before execution.



Used wrappers
---------------------

The following individual wrappers are used in this meta-wrapper:


* :ref:`bio/salmon/generate_decoy`

* :ref:`bio/salmon/index`

* :ref:`bio/salmon/quant`


Please refer to each wrapper in above list for additional configuration parameters and information about the executed code.







Authors
-------


* Thibault Dayris

